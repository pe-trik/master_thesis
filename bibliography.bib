%
%  An example of a bibliographical database for bibTeX
%
%  Recommended software for maintenance of *.bib files:
%    JabRef, http://jabref.sourceforge.net/
%
%  BEWARE:
%
%    *  If a name contains a capital letter, which must be kept such,
%       use curly brackets ({T}hailand, {HIV}).
%
%  ===========================================================================

@article{rumelhart1986learning,
  title={Learning representations by back-propagating errors},
  author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
  journal={nature},
  volume={323},
  number={6088},
  pages={533--536},
  year={1986},
  publisher={Nature Publishing Group}
}


@article{juang2005automatic,
  title={Automatic speech recognition--a brief history of the technology development},
  author={Juang, Biing-Hwang and Rabiner, Lawrence R},
  journal={Georgia Institute of Technology. Atlanta Rutgers University and the University of California. Santa Barbara},
  volume={1},
  pages={67},
  year={2005}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017}
}

@inproceedings{gehring2017convolutional,
  title={Convolutional sequence to sequence learning},
  author={Gehring, Jonas and Auli, Michael and Grangier, David and Yarats, Denis and Dauphin, Yann N},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1243--1252},
  year={2017},
  organization={JMLR. org}
}

@article{bahdanau2014neural,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1409.0473},
  year={2014}
}


@article{ma2018stacl,
  title={Stacl: Simultaneous translation with integrated anticipation and controllable latency},
  author={Ma, Mingbo and Huang, Liang and Xiong, Hao and Liu, Kaibo and Zhang, Chuanqiang and He, Zhongjun and Liu, Hairong and Li, Xing and Wang, Haifeng},
  journal={arXiv preprint arXiv:1810.08398},
  year={2018}
}

@article{zheng2019simultaneous,
  title={Simultaneous Translation with Flexible Policy via Restricted Imitation Learning},
  author={Zheng, Baigong and Zheng, Renjie and Ma, Mingbo and Huang, Liang},
  journal={arXiv preprint arXiv:1906.01135},
  year={2019}
}

@article{zheng2019simpler,
  title={Simpler and faster learning of adaptive policies for simultaneous translation},
  author={Zheng, Baigong and Zheng, Renjie and Ma, Mingbo and Huang, Liang},
  journal={arXiv preprint arXiv:1909.01559},
  year={2019}
}

@article{zheng2019speculative,
  title={Speculative Beam Search for Simultaneous Translation},
  author={Zheng, Renjie and Ma, Mingbo and Zheng, Baigong and Huang, Liang},
  journal={arXiv preprint arXiv:1909.05421},
  year={2019}
}

@inproceedings{salesky-etal-2019-exploring,
    title = "Exploring Phoneme-Level Speech Representations for End-to-End Speech Translation",
    author = "Salesky, Elizabeth  and
      Sperber, Matthias  and
      Black, Alan W",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P19-1179",
    doi = "10.18653/v1/P19-1179",
    pages = "1835--1841",
    abstract = "Previous work on end-to-end translation from speech has primarily used frame-level features as speech representations, which creates longer, sparser sequences than text. We show that a naive method to create compressed phoneme-like speech representations is far more effective and efficient for translation than traditional frame-level speech features. Specifically, we generate phoneme labels for speech frames and average consecutive frames with the same label to create shorter, higher-level source sequences for translation. We see improvements of up to 5 BLEU on both our high and low resource language pairs, with a reduction in training time of 60{\%}. Our improvements hold across multiple data sizes and two language pairs.",
}

@inproceedings{zhou2018comparison,
  title={A comparison of modeling units in sequence-to-sequence speech recognition with the transformer on mandarin chinese},
  author={Zhou, Shiyu and Dong, Linhao and Xu, Shuang and Xu, Bo},
  booktitle={International Conference on Neural Information Processing},
  pages={210--220},
  year={2018},
  organization={Springer}
}

@article{zhou2018syllable,
  title={Syllable-based sequence-to-sequence speech recognition with the transformer in mandarin chinese},
  author={Zhou, Shiyu and Dong, Linhao and Xu, Shuang and Xu, Bo},
  journal={arXiv preprint arXiv:1804.10752},
  year={2018}
}


@article{han2019state,
  title={State-of-the-Art Speech Recognition Using Multi-Stream Self-Attention With Dilated 1D Convolutions},
  author={Han, Kyu J and Prieto, Ramon and Wu, Kaixing and Ma, Tao},
  journal={arXiv preprint arXiv:1910.00716},
  year={2019}
}

@inproceedings{panayotov2015librispeech,
  title={Librispeech: an ASR corpus based on public domain audio books},
  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={5206--5210},
  year={2015},
  organization={IEEE}
}

@INPROCEEDINGS{
         Kaldi,
         author = {Povey, Daniel and Ghoshal, Arnab and Boulianne, Gilles and Burget, Lukas and Glembek, Ondrej and Goel, Nagendra and Hannemann, Mirko and Motlicek, Petr and Qian, Yanmin and Schwarz, Petr and Silovsky, Jan and Stemmer, Georg and Vesely, Karel},
       keywords = {ASR, Automatic Speech Recognition, GMM, HTK, SGMM},
          month = dec,
          title = {The Kaldi Speech Recognition Toolkit},
      booktitle = {IEEE 2011 Workshop on Automatic Speech Recognition and Understanding},
           year = {2011},
      publisher = {IEEE Signal Processing Society},
       location = {Hilton Waikoloa Village, Big Island, Hawaii, US},
           note = {IEEE Catalog No.: CFP11SRW-USB},
}

@misc{dataset,
  title="{Large Corpus of Czech Parliament Plenary Hearings}",
  author={Kratochvíl, Jonáš and Polák, Peter and Bojar, Ondřej },
  publisher = {Charles University, Faculty of Mathematics and Physics, Institute of Formal and Applied Linguistics (UFAL)},
  howpublished = {\url{http://hdl.handle.net/11234/1-3126}},
  year={2019},
}

@article{kriman2019quartznet,
  title={QuartzNet: Deep Automatic Speech Recognition with 1D Time-Channel Separable Convolutions},
  author={Kriman, Samuel and Beliaev, Stanislav and Ginsburg, Boris and Huang, Jocelyn and Kuchaiev, Oleksii and Lavrukhin, Vitaly and Leary, Ryan and Li, Jason and Zhang, Yang},
  journal={arXiv preprint arXiv:1910.10261},
  year={2019}
}

@inproceedings{kunze-etal-2017-transfer,
    title = "Transfer Learning for Speech Recognition on a Budget",
    author = "Kunze, Julius  and
      Kirsch, Louis  and
      Kurenkov, Ilia  and
      Krug, Andreas  and
      Johannsmeier, Jens  and
      Stober, Sebastian",
    booktitle = "Proceedings of the 2nd Workshop on Representation Learning for {NLP}",
    month = aug,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W17-2620",
    doi = "10.18653/v1/W17-2620",
    pages = "168--177",
    abstract = "End-to-end training of automated speech recognition (ASR) systems requires massive data and compute resources. We explore transfer learning based on model adaptation as an approach for training ASR models under constrained GPU memory, throughput and training data. We conduct several systematic experiments adapting a Wav2Letter convolutional neural network originally trained for English ASR to the German language. We show that this technique allows faster training on consumer-grade resources while requiring less training data in order to achieve the same accuracy, thereby lowering the cost of training ASR models in other languages. Model introspection revealed that small adaptations to the network{'}s weights were sufficient for good performance, especially for inner layers.",
}

@inproceedings{cho2018multilingual,
  title={Multilingual sequence-to-sequence speech recognition: architecture, transfer learning, and language modeling},
  author={Cho, Jaejin and Baskar, Murali Karthick and Li, Ruizhi and Wiesner, Matthew and Mallidi, Sri Harish and Yalta, Nelson and Karafiat, Martin and Watanabe, Shinji and Hori, Takaaki},
  booktitle={2018 IEEE Spoken Language Technology Workshop (SLT)},
  pages={521--527},
  year={2018},
  organization={IEEE}
}

@inproceedings{zoph-etal-2016-transfer,
    title = "Transfer Learning for Low-Resource Neural Machine Translation",
    author = "Zoph, Barret  and
      Yuret, Deniz  and
      May, Jonathan  and
      Knight, Kevin",
    booktitle = "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2016",
    address = "Austin, Texas",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D16-1163",
    doi = "10.18653/v1/D16-1163",
    pages = "1568--1575",
}

@inproceedings{kocmi-bojar-2018-trivial,
    title = "Trivial Transfer Learning for Low-Resource Neural Machine Translation",
    author = "Kocmi, Tom  and
      Bojar, Ond{\v{r}}ej",
    booktitle = "Proceedings of the Third Conference on Machine Translation: Research Papers",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6325",
    doi = "10.18653/v1/W18-6325",
    pages = "244--252",
}


@misc{nemo2019,
    title={NeMo: a toolkit for building AI applications using Neural Modules}, author={Oleksii Kuchaiev and Jason Li and Huyen Nguyen and Oleksii Hrinchuk and Ryan Leary and Boris Ginsburg and Samuel Kriman and Stanislav Beliaev and Vitaly Lavrukhin and Jack Cook and Patrice Castonguay and Mariya Popova and Jocelyn Huang and Jonathan M. Cohen}, year={2019}, eprint={1909.09577}, archivePrefix={arXiv}, primaryClass={cs.LG}

}

@inproceedings{Li2019,
  author={Jason Li and Vitaly Lavrukhin and Boris Ginsburg and Ryan Leary and Oleksii Kuchaiev and Jonathan M. Cohen and Huyen Nguyen and Ravi Teja Gadde},
  title={{Jasper: An End-to-End Convolutional Neural Acoustic Model}},
  year=2019,
  booktitle={Proc. Interspeech 2019},
  pages={71--75},
  doi={10.21437/Interspeech.2019-1819},
  url={http://dx.doi.org/10.21437/Interspeech.2019-1819}
}

@inproceedings{tan2018survey,
  title={A Survey on Deep Transfer Learning},
  author={Tan, Chuanqi and Sun, Fuchun and Kong, Tao and Zhang, Wenchang and Yang, Chao and Liu, Chunfang},
  booktitle={International Conference on Artificial Neural Networks},
  pages={270--279},
  year={2018},
  organization={Springer}
}

@INPROCEEDINGS{coarse-to-fine-hyperparam:2017,
author={V. {Moshkelgosha} and H. {Behzadi-Khormouji} and M. {Yazdian-Dehkordi}},
booktitle={2017 3rd International Conference on Pattern Recognition and Image Analysis (IPRIA)},
title={Coarse-to-fine parameter tuning for content-based object categorization},
year={2017},
volume={},
number={},
pages={160-165},
keywords={computer vision;feature extraction;image classification;visual databases;content-based object categorization;computer vision;cross validation;feature descriptors;hybrid feature descriptor;coarse-to-fine parameter tuning method;hyper-parameter;COREL dataset;hybrid feature;tuning parameters;Histograms;Tuning;Image color analysis;Classification algorithms;Computer vision;Support vector machine classification;Corel dataset;image classification;k-nearest neighbor;Support Vector Machine;AdaBoostM2;feature descriptor},
doi={10.1109/PRIA.2017.7983038},
ISSN={null},
month={April},}


@InProceedings{charniak:etal:2006,
  title =	"Multilevel Coarse-to-Fine {PCFG} Parsing",
  author =	"Eugene Charniak and Mark Johnson and Micha Elsner and
		 Joseph Austerweil and David Ellis and Isaac Haxton and
		 Catherine Hill and R. Shrivaths and Jeremy Moore and
		 Michael Pozar and Theresa Vu",
  bibdate =	"2006-12-20",
  bibsource =	"DBLP,
		 http://dblp.uni-trier.de/db/conf/naacl/naacl2006.html#CharniakJEAEHHSMPV06",
  booktitle =	"HLT-NAACL",
  booktitle =	"Human Language Technology Conference of the North
		 American Chapter of the Association of Computational
		 Linguistics, Proceedings, June 4-9, 2006, New York, New
		 York, {USA}",
  publisher =	"The Association for Computational Linguistics",
  year = 	"2006",
  editor =	"Robert C. Moore and Jeff A. Bilmes and Jennifer
		 Chu-Carroll and Mark Sanderson",
  URL =  	"http://acl.ldc.upenn.edu/N/N06/N06-1022.pdf",
}

@inproceedings{dong-lapata-2018-coarse,
    title = "Coarse-to-Fine Decoding for Neural Semantic Parsing",
    author = "Dong, Li  and
      Lapata, Mirella",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P18-1068",
    doi = "10.18653/v1/P18-1068",
    pages = "731--742",
    abstract = "Semantic parsing aims at mapping natural language utterances into structured meaning representations. In this work, we propose a structure-aware neural architecture which decomposes the semantic parsing process into two stages. Given an input utterance, we first generate a rough sketch of its meaning, where low-level information (such as variable names and arguments) is glossed over. Then, we fill in missing details by taking into account the natural language input and the sketch itself. Experimental results on four datasets characteristic of different domains and meaning representations show that our approach consistently improves performance, achieving competitive results despite the use of relatively simple decoders.",
}

@ARTICLE{raphael:coarse-to-fine:2001,
author={C. {Raphael}},
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
title={Coarse-to-fine dynamic programming},
year={2001},
volume={23},
number={12},
pages={1379-1390},
keywords={dynamic programming;object recognition;approximation theory;iterative methods;graph theory;dynamic programming;mine recognition;iterated complete path;global optimization;coarse approximations;graph theory;Dynamic programming;Cost function;State-space methods;Character recognition;Speech recognition;Merging;Convergence;Decoding;Roads;Approximation algorithms},
doi={10.1109/34.977562},
ISSN={1939-3539},
month={Dec},}

@InProceedings{coarse-to-fine-nmt:word-repr:2018,
author="Zhang, Zhirui
and Liu, Shujie
and Li, Mu
and Zhou, Ming
and Chen, Enhong",
editor="Zhang, Min
and Ng, Vincent
and Zhao, Dongyan
and Li, Sujian
and Zan, Hongying",
title="Coarse-To-Fine Learning for Neural Machine Translation",
booktitle="Natural Language Processing and Chinese Computing",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="316--328",
abstract="In this paper, we address the problem of learning better word representations for neural machine translation (NMT). We propose a novel approach to NMT model training based on coarse-to-fine learning paradigm, which is able to infer better NMT model parameters for a wide range of less-frequent words in the vocabulary. To this end, our proposed method first groups source and target words into a set of hierarchical clusters, then a sequence of NMT models are learned based on it with growing cluster granularity. Each subsequent model inherits model parameters from its previous one and refines them with finer-grained word-cluster mapping. Experimental results on public data sets demonstrate that our proposed method significantly outperforms baseline attention-based NMT model on Chinese-English and English-French translation tasks.",
isbn="978-3-319-99495-6"
}

@InProceedings{karita2019comparative,
  title={A comparative study on transformer vs rnn in speech applications},
  author={Karita, Shigeki and Chen, Nanxin and Hayashi, Tomoki and Hori, Takaaki and Inaguma, Hirofumi and Jiang, Ziyan and Someki, Masao and Soplin, Nelson Enrique Yalta and Yamamoto, Ryuichi and Wang, Xiaofei and others},
  booktitle="Proceedings of the ASRU 2019 IEEE Automatic Speech Recognition and Understanding Workshop",
  note="(in print)",
  year={2019}
}

@article{TONG201839,
title = "Cross-lingual adaptation of a CTC-based multilingual acoustic model",
journal = "Speech Communication",
volume = "104",
pages = "39 - 46",
year = "2018",
issn = "0167-6393",
doi = "https://doi.org/10.1016/j.specom.2018.09.001",
url = "http://www.sciencedirect.com/science/article/pii/S016763931830030X",
author = "Sibo Tong and Philip N. Garner and Hervé Bourlard",
keywords = "Multilingual Automatic Speech Recognition (ASR), Connectionist Temporal Classification (CTC), Cross-lingual adaptation, Learning Hidden Unit Contribution (LHUC), Dropout",
abstract = "Multilingual models for Automatic Speech Recognition (ASR) are attractive as they have been shown to benefit from more training data, and better lend themselves to adaptation to under-resourced languages. However, initialisation from monolingual context-dependent models leads to an explosion of context-dependent states. Connectionist Temporal Classification (CTC) is a potential solution to this as it performs well with monophone labels. We investigate multilingual CTC training in the context of adaptation and regularisation techniques that have been shown to be beneficial in more conventional contexts. The multilingual model is trained to model a universal International Phonetic Alphabet (IPA)-based phone set using the CTC loss function. Learning Hidden Unit Contribution (LHUC) is investigated to perform language adaptive training. During cross-lingual adaptation, the idea of extending the multilingual output layer to new phonemes is introduced and investigated. In addition, dropout during multilingual training and cross-lingual adaptation is also studied and tested in order to mitigate the overfitting problem. Experiments show that the performance of the universal phoneme-based CTC system can be improved by applying dropout and LHUC and it is extensible to new phonemes during cross-lingual adaptation. Updating all acoustic model parameters shows consistent improvement on limited data. Applying dropout during adaptation can further improve the system and achieve competitive performance with Deep Neural Network / Hidden Markov Model (DNN/HMM) systems on limited data."
}

@INPROCEEDINGS{kim,
author={S. {Kim} and M. L. {Seltzer}},
booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
title={Towards Language-Universal End-to-End Speech Recognition},
year={2018},
volume={},
number={},
pages={4914-4918},
keywords={character sets;language translation;learning (artificial intelligence);linguistics;natural language processing;neural nets;speech processing;speech recognition;single multilingual speech recognition system;universal character;language-specific gating mechanism;language-specific way;individual monolingual systems;multitask learning approach;monolingual speech recognizer;language-universal end-to-end speech recognition;multiple languages;monolingual training recipe;networks internal representation;Microsoft Cortana task;Speech recognition;Training;Acoustics;Task analysis;Data models;Computational modeling;Adaptation models;multilingual;language-universal},
doi={10.1109/ICASSP.2018.8462201},
ISSN={2379-190X},
month={April},}

@article{hrinchuk2019correction,
  title={Correction of Automatic Speech Recognition with Transformer Sequence-to-sequence Model},
  author={Hrinchuk, Oleksii and Popova, Mariya and Ginsburg, Boris},
  journal={arXiv preprint arXiv:1910.10697},
  year={2019}
}

@inproceedings{denkowski2017stronger,
  title={Stronger Baselines for Trustable Results in Neural Machine Translation},
  author={Denkowski, Michael and Neubig, Graham},
  booktitle={Proceedings of the First Workshop on Neural Machine Translation},
  pages={18--27},
  year={2017}
}

@article{gupta2019character,
  title={Character-based NMT with Transformer},
  author={Gupta, Rohit and Besacier, Laurent and Dymetman, Marc and Gall{\'e}, Matthias},
  journal={arXiv preprint arXiv:1911.04997},
  year={2019}
}

@inproceedings{ding2019call,
  title={A Call for Prudent Choice of Subword Merge Operations in Neural Machine Translation},
  author={Ding, Shuoyang and Renduchintala, Adithya and Duh, Kevin},
  booktitle={Proceedings of Machine Translation Summit XVII Volume 1: Research Track},
  pages={204--213},
  year={2019}
}

@inproceedings{papineni2002bleu,
  title={BLEU: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting on association for computational linguistics},
  pages={311--318},
  year={2002},
  organization={Association for Computational Linguistics}
}

@inproceedings{post2018call,
  title={A Call for Clarity in Reporting BLEU Scores},
  author={Post, Matt},
  booktitle={Proceedings of the Third Conference on Machine Translation: Research Papers},
  pages={186--191},
  year={2018}
}


@article{waibel1989phoneme,
  title={Phoneme recognition using time-delay neural networks},
  author={Waibel, Alex and Hanazawa, Toshiyuki and Hinton, Geoffrey and Shikano, Kiyohiro and Lang, Kevin J},
  journal={IEEE transactions on acoustics, speech, and signal processing},
  volume={37},
  number={3},
  pages={328--339},
  year={1989},
  publisher={IEEE}
}

@inproceedings{lubensky1988learning,
  title={Learning spectral-temporal dependencies using connectionist networks},
  author={Lubensky, David},
  booktitle={ICASSP-88., International Conference on Acoustics, Speech, and Signal Processing},
  pages={418--421},
  year={1988},
  organization={IEEE}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@inproceedings{cherry2018revisiting,
  title={Revisiting Character-Based Neural Machine Translation with Capacity and Compression},
  author={Cherry, Colin and Foster, George and Bapna, Ankur and Firat, Orhan and Macherey, Wolfgang},
  booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  pages={4295--4305},
  year={2018}
}

@article{muda2010voice,
  title={Voice recognition algorithms using mel frequency cepstral coefficient (MFCC) and dynamic time warping (DTW) techniques},
  author={Muda, Lindasalwa and Begam, Mumtaj and Elamvazuthi, Irraivan},
  journal={arXiv preprint arXiv:1003.4083},
  year={2010}
}

@book{kamath2019deep,
  title={Deep learning for nlp and speech recognition},
  author={Kamath, Uday and Liu, John and Whitaker, James},
  year={2019},
  publisher={Springer}
}

@inproceedings{huang2017densely,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4700--4708},
  year={2017}
}

@article{tang2018acoustic,
  title={Acoustic Modeling with Densely Connected Residual Network for Multichannel Speech Recognition},
  author={Tang, Jian and Song, Yan and Dai, Lirong and McLoughlin, Ian},
  journal={Proc. Interspeech 2018},
  pages={1783--1787},
  year={2018}
}

@article{li2019jasper,
  title={Jasper: An end-to-end convolutional neural acoustic model},
  author={Li, Jason and Lavrukhin, Vitaly and Ginsburg, Boris and Leary, Ryan and Kuchaiev, Oleksii and Cohen, Jonathan M and Nguyen, Huyen and Gadde, Ravi Teja},
  journal={arXiv preprint arXiv:1904.03288},
  year={2019}
}

@inproceedings{barrault2019findings,
  title={Findings of the 2019 conference on machine translation (wmt19)},
  author={Barrault, Lo{\"\i}c and Bojar, Ond{\v{r}}ej and Costa-juss{\`a}, Marta R and Federmann, Christian and Fishel, Mark and Graham, Yvette and Haddow, Barry and Huck, Matthias and Koehn, Philipp and Malmasi, Shervin and others},
  booktitle={Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)},
  pages={1--61},
  year={2019}
}

@inproceedings{bojar2018proceedings,
  title={Proceedings of the Third Conference on Machine Translation: Shared Task Papers},
  author={Bojar, Ond{\v{r}}ej and Chatterjee, Rajen and Federmann, Christian and Fishel, Mark and Graham, Yvette and Haddow, Barry and Huck, Matthias and Yepes, Antonio Jimeno and Koehn, Philipp and Monz, Christof and others},
  booktitle={Proceedings of the Third Conference on Machine Translation: Shared Task Papers},
  year={2018}
}

@inproceedings{paul1992design,
  title={The design for the Wall Street Journal-based CSR corpus},
  author={Paul, Douglas B and Baker, Janet M},
  booktitle={Proceedings of the workshop on Speech and Natural Language},
  pages={357--362},
  year={1992},
  organization={Association for Computational Linguistics}
}

@article{ardila2019common,
  title={Common Voice: A Massively-Multilingual Speech Corpus},
  author={Ardila, Rosana and Branson, Megan and Davis, Kelly and Henretty, Michael and Kohler, Michael and Meyer, Josh and Morais, Reuben and Saunders, Lindsay and Tyers, Francis M and Weber, Gregor},
  journal={arXiv preprint arXiv:1912.06670},
  year={2019}
}

@article{luong2014addressing,
  title={Addressing the rare word problem in neural machine translation},
  author={Luong, Minh-Thang and Sutskever, Ilya and Le, Quoc V and Vinyals, Oriol and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1410.8206},
  year={2014}
}

@inproceedings{luong2016achieving,
  title={Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models},
  author={Luong, Minh-Thang and Manning, Christopher D},
  booktitle={Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={1054--1063},
  year={2016}
}

@inproceedings{sennrich2016neural,
  title={Neural Machine Translation of Rare Words with Subword Units},
  author={Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
  booktitle={Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={1715--1725},
  year={2016}
}

@inproceedings{kudo2018subword,
  title={Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates},
  author={Kudo, Taku},
  booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={66--75},
  year={2018}
}

@article{provilkov2019bpe,
  title={BPE-Dropout: Simple and Effective Subword Regularization},
  author={Provilkov, Ivan and Emelianenko, Dmitrii and Voita, Elena},
  journal={arXiv preprint arXiv:1910.13267},
  year={2019}
}

@inproceedings{bojar2016czeng,
	title={CzEng 1.6: enlarged czech-english parallel corpus with processing tools dockered},
	author={Bojar, Ond{\v{r}}ej and Du{\v{s}}ek, Ond{\v{r}}ej and Kocmi, Tom and Libovick{\`y}, Jind{\v{r}}ich and Nov{\'a}k, Michal and Popel, Martin and Sudarikov, Roman and Vari{\v{s}}, Du{\v{s}}an},
	booktitle={International Conference on Text, Speech, and Dialogue},
	pages={231--238},
	year={2016},
	organization={Springer}
}

@article{padmanabhan2015machine,
	title={Machine learning in automatic speech recognition: A survey},
	author={Padmanabhan, Jayashree and Johnson Premkumar, Melvin Jose},
	journal={IETE Technical Review},
	volume={32},
	number={4},
	pages={240--251},
	year={2015},
	publisher={Taylor \& Francis}
}

@inproceedings{amodei2016deep,
	title={Deep speech 2: End-to-end speech recognition in english and mandarin},
	author={Amodei, Dario and Ananthanarayanan, Sundaram and Anubhai, Rishita and Bai, Jingliang and Battenberg, Eric and Case, Carl and Casper, Jared and Catanzaro, Bryan and Cheng, Qiang and Chen, Guoliang and others},
	booktitle={International conference on machine learning},
	pages={173--182},
	year={2016}
}

@article{chorowski2014end,
	title={End-to-end continuous speech recognition using attention-based recurrent nn: First results},
	author={Chorowski, Jan and Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
	journal={arXiv preprint arXiv:1412.1602},
	year={2014}
}

@article{berard2016listen,
	title={Listen and translate: A proof of concept for end-to-end speech-to-text translation},
	author={B{\'e}rard, Alexandre and Pietquin, Olivier and Servan, Christophe and Besacier, Laurent},
	journal={arXiv preprint arXiv:1612.01744},
	year={2016}
}

@inproceedings{berard2018end,
	title={End-to-end automatic speech translation of audiobooks},
	author={B{\'e}rard, Alexandre and Besacier, Laurent and Kocabiyikoglu, Ali Can and Pietquin, Olivier},
	booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	pages={6224--6228},
	year={2018},
	organization={IEEE}
}

@inproceedings{jia2019leveraging,
	title={Leveraging weakly supervised data to improve end-to-end speech-to-text translation},
	author={Jia, Ye and Johnson, Melvin and Macherey, Wolfgang and Weiss, Ron J and Cao, Yuan and Chiu, Chung-Cheng and Ari, Naveen and Laurenzo, Stella and Wu, Yonghui},
	booktitle={ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	pages={7180--7184},
	year={2019},
	organization={IEEE}
}

@article{sperber2019attention,
	title={Attention-passing models for robust and data-efficient end-to-end speech translation},
	author={Sperber, Matthias and Neubig, Graham and Niehues, Jan and Waibel, Alex},
	journal={Transactions of the Association for Computational Linguistics},
	volume={7},
	pages={313--325},
	year={2019},
	publisher={MIT Press}
}

@book{yu2016automatic,
	title={AUTOMATIC SPEECH RECOGNITION.},
	author={Yu, Dong and Deng, Li},
	year={2016},
	publisher={Springer}
}

@inproceedings{chen2014joint,
	title={Joint acoustic modeling of triphones and trigraphemes by multi-task learning deep neural networks for low-resource speech recognition},
	author={Chen, Dongpeng and Mak, Brian and Leung, Cheung-Chi and Sivadas, Sunil},
	booktitle={2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	pages={5592--5596},
	year={2014},
	organization={IEEE}
}

@inproceedings{seltzer2013multi,
	title={Multi-task learning in deep neural networks for improved phoneme recognition},
	author={Seltzer, Michael L and Droppo, Jasha},
	booktitle={2013 IEEE International Conference on Acoustics, Speech and Signal Processing},
	pages={6965--6969},
	year={2013},
	organization={IEEE}
}

@inproceedings{mohamed2009deep,
	title={Deep belief networks for phone recognition},
	author={Mohamed, Abdel-rahman and Dahl, George and Hinton, Geoffrey},
	booktitle={Nips workshop on deep learning for speech recognition and related applications},
	volume={1},
	number={9},
	pages={39},
	year={2009},
	organization={Vancouver, Canada}
}

@inproceedings{riley1992recognizing,
	title={Recognizing phonemes vs. recognizing phones: a comparison},
	author={Riley, Michael D and Ljolje, Andrej},
	booktitle={Second International Conference on Spoken Language Processing},
	year={1992}
}

@inproceedings{fiscus1997post,
	title={A post-processing system to yield reduced word error rates: Recognizer output voting error reduction (ROVER)},
	author={Fiscus, Jonathan G},
	booktitle={1997 IEEE Workshop on Automatic Speech Recognition and Understanding Proceedings},
	pages={347--354},
	year={1997},
	organization={IEEE}
}

@ARTICLE{1161968,  author={D. {Reddy} and A. {Robinson}},  journal={IEEE Transactions on Audio and Electroacoustics},  title={Phoneme-to-grapheme translation of english},   year={1968},  volume={16},  number={2},  pages={240-246},}

@INPROCEEDINGS{1034672,  author={B. {Decadt} and J. {Duchateau} and W. {Daelemans} and P. {Wambacq}},  booktitle={IEEE Workshop on Automatic Speech Recognition and Understanding, 2001. ASRU '01.},  title={Phoneme-to-grapheme conversion for out-of-vocabulary words in large vocabulary speech recognition},   year={2001},  volume={},  number={},  pages={413-416},}

@inproceedings{horndasch2006phoneme,
	title={Phoneme-to-grapheme mapping for spoken inquiries to the semantic web},
	author={Horndasch, Axel and N{\"o}th, Elmar and Batliner, Anton and Warnke, Volker},
	booktitle={Ninth International Conference on Spoken Language Processing},
	year={2006}
}

@article{basson2013category,
	title={Category-based phoneme-to-grapheme transliteration},
	author={Basson, Willem D and Davel, Marelie H},
	year={2013},
	publisher={International Speech Communication Association (ISCA)}
}

@article{popel2018training,
	title={Training tips for the transformer model},
	author={Popel, Martin and Bojar, Ond{\v{r}}ej},
	journal={The Prague Bulletin of Mathematical Linguistics},
	volume={110},
	number={1},
	pages={43--70},
	year={2018},
	publisher={De Gruyter Open}
}

@article{weiss2017sequence,
	title={Sequence-to-Sequence Models Can Directly Translate Foreign Speech},
	author={Weiss, Ron J and Chorowski, Jan and Jaitly, Navdeep and Wu, Yonghui and Chen, Zhifeng},
	journal={Proc. Interspeech 2017},
	pages={2625--2629},
	year={2017}
}

@article{zhang2017towards,
	title={Towards end-to-end speech recognition with deep convolutional neural networks},
	author={Zhang, Ying and Pezeshki, Mohammad and Brakel, Phil{\'e}mon and Zhang, Saizheng and Bengio, Cesar Laurent Yoshua and Courville, Aaron},
	journal={arXiv preprint arXiv:1701.02720},
	year={2017}
}

@article{hannun2014deep,
	title={Deep speech: Scaling up end-to-end speech recognition},
	author={Hannun, Awni and Case, Carl and Casper, Jared and Catanzaro, Bryan and Diamos, Greg and Elsen, Erich and Prenger, Ryan and Satheesh, Sanjeev and Sengupta, Shubho and Coates, Adam and others},
	journal={arXiv preprint arXiv:1412.5567},
	year={2014}
}

@inproceedings{graves2006connectionist,
	title={Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks},
	author={Graves, Alex and Fern{\'a}ndez, Santiago and Gomez, Faustino and Schmidhuber, J{\"u}rgen},
	booktitle={Proceedings of the 23rd international conference on Machine learning},
	pages={369--376},
	year={2006}
}

@inproceedings{bahdanau2016end,
	title={End-to-end attention-based large vocabulary speech recognition},
	author={Bahdanau, Dzmitry and Chorowski, Jan and Serdyuk, Dmitriy and Brakel, Philemon and Bengio, Yoshua},
	booktitle={2016 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
	pages={4945--4949},
	year={2016},
	organization={IEEE}
}

@article{stevens1937scale,
	title={A scale for the measurement of the psychological magnitude pitch},
	author={Stevens, Stanley Smith and Volkmann, John and Newman, Edwin B},
	journal={The Journal of the Acoustical Society of America},
	volume={8},
	number={3},
	pages={185--190},
	year={1937},
	publisher={Acoustical Society of America}
}
